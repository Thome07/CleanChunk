## üß† CleanChunk ‚Äì Chunk Sem√¢ntico Inteligente em JSON
Transforme documentos extensos (PDF, DOCX, TXT) em chunks sem√¢nticos limpos e estruturados em JSON, prontos para NLP, RAG, chatbots ou an√°lise de conte√∫do.

### ‚öôÔ∏è Funcionalidades
Suporte a arquivos: PDF, DOCX, TXT

3 modos de chunking:

üìñ Texto Livre: Chunks coesos validados semanticamente

‚ùì FAQ: Perguntas e respostas detectadas automaticamente

üé§ Entrevista: Pares pergunta‚Äìresposta extra√≠dos por turnos de fala

Sa√≠da JSON estruturada: Inclui metadados como p√°gina, coes√£o e similaridade

NLP Inteligente:

Sentence Transformers

Threshold ajust√°vel de similaridade (slider)

Valida√ß√£o gramatical, sem√¢ntica e remo√ß√£o de ru√≠do

### üöÄ Como Usar
Instale as depend√™ncias:
```
pip install -r requirements.txt
``` 
Rode a interface:

```
python Main.py
```
No app:

Selecione o arquivo (PDF, DOCX ou TXT)

Escolha o tipo de conte√∫do (Texto, FAQ, Entrevista)

Ajuste o n√≠vel de similaridade (0.5‚Äì0.9)

Clique em Processar Arquivo

Salve o resultado em JSON

### üì§ Exemplo de Sa√≠da (JSON)
```json
{
  "chunk_id": 1,
  "conteudo": "Texto processado...",
  "pagina": 3,
  "similaridade_media": 0.82,
  "coesao_interna": 0.79
}
```
### üß™ Tecnologias
NLP: sentence-transformers, transformers (opcional)

PDFs: pdfplumber

Interface: tkinter (com tema escuro)

Limpeza de texto: unidecode, ftfy

### üí° Dicas
Use o modo "Cont√©m Cabe√ßalhos" para melhores resultados em documentos estruturados

Recomendado manter os modelos NLP atualizados

Arquivos grandes (>100 p√°ginas) podem exigir mais RAM

